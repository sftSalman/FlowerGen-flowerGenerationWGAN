{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = self._block(channels_img, features_d, 4, 2, 1)\n",
    "        self.conv2 = self._block(features_d, features_d * 2, 4, 2, 1)\n",
    "        self.conv3 = self._block(features_d * 2, features_d * 4, 4, 2, 1)\n",
    "        self.conv4 = self._block(features_d * 4, features_d * 8, 4, 2, 1)\n",
    "        self.conv5 = nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0)\n",
    "       \n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = self._block(channels_noise, features_g * 16, 4, 1, 0)  # img: 4x4\n",
    "        self.conv2 = self._block(features_g * 16, features_g * 8, 4, 2, 1)  # img: 8x8\n",
    "        self.conv3 = self._block(features_g * 8, features_g * 4, 4, 2, 1)  # img: 16x16\n",
    "        self.conv4 = self._block(features_g * 4, features_g * 2, 4, 2, 1)  # img: 32x32\n",
    "        self.conv5 = nn.ConvTranspose2d(features_g * 2, channels_img, kernel_size=4, stride=2, padding=1)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_path = \"generator.pth\"\n",
    "critic_loss_path = \"critic_loss.pth\"\n",
    "gen_loss_path = \"gen_loss.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), generator_path)\n",
    "torch.save(loss_critic.item(), critic_loss_path)\n",
    "torch.save(loss_gen.item(), gen_loss_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if saved files exist and load them\n",
    "import os\n",
    "if os.path.exists(generator_path):\n",
    "    gen.load_state_dict(torch.load(generator_path))\n",
    "if os.path.exists(critic_loss_path):\n",
    "    critic_loss = torch.load(critic_loss_path)\n",
    "if os.path.exists(gen_loss_path):\n",
    "    gen_loss = torch.load(gen_loss_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 101/103 [00:50<00:01,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20] Batch 100/103                   Loss D: -1.2555, loss G: 0.6082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:50<00:00,  2.03it/s]\n",
      " 98%|█████████▊| 101/103 [00:48<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Batch 100/103                   Loss D: -1.4160, loss G: 0.7134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:49<00:00,  2.08it/s]\n",
      " 98%|█████████▊| 101/103 [00:47<00:01,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] Batch 100/103                   Loss D: -1.4707, loss G: 0.7204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:47<00:00,  2.15it/s]\n",
      " 98%|█████████▊| 101/103 [00:45<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] Batch 100/103                   Loss D: -1.4615, loss G: 0.7202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:46<00:00,  2.23it/s]\n",
      " 98%|█████████▊| 101/103 [00:47<00:01,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] Batch 100/103                   Loss D: -1.4504, loss G: 0.7067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:48<00:00,  2.12it/s]\n",
      " 98%|█████████▊| 101/103 [00:48<00:01,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] Batch 100/103                   Loss D: -1.4278, loss G: 0.7048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:49<00:00,  2.08it/s]\n",
      " 98%|█████████▊| 101/103 [00:49<00:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] Batch 100/103                   Loss D: -1.4264, loss G: 0.7053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:49<00:00,  2.06it/s]\n",
      " 98%|█████████▊| 101/103 [00:48<00:01,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] Batch 100/103                   Loss D: -1.3750, loss G: 0.7122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:49<00:00,  2.08it/s]\n",
      " 98%|█████████▊| 101/103 [00:48<00:01,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] Batch 100/103                   Loss D: -1.4076, loss G: 0.6945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:48<00:00,  2.11it/s]\n",
      " 98%|█████████▊| 101/103 [00:48<00:01,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] Batch 100/103                   Loss D: -1.3423, loss G: 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:49<00:00,  2.09it/s]\n",
      " 98%|█████████▊| 101/103 [00:48<00:01,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] Batch 100/103                   Loss D: -1.3978, loss G: 0.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:49<00:00,  2.08it/s]\n",
      " 98%|█████████▊| 101/103 [00:48<00:01,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] Batch 100/103                   Loss D: -1.3545, loss G: 0.6682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:49<00:00,  2.08it/s]\n",
      " 98%|█████████▊| 101/103 [00:47<00:01,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] Batch 100/103                   Loss D: -1.3646, loss G: 0.6704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:48<00:00,  2.13it/s]\n",
      " 98%|█████████▊| 101/103 [00:45<00:01,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] Batch 100/103                   Loss D: -1.2902, loss G: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:46<00:00,  2.21it/s]\n",
      " 98%|█████████▊| 101/103 [00:48<00:01,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] Batch 100/103                   Loss D: -1.3332, loss G: 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:49<00:00,  2.08it/s]\n",
      " 98%|█████████▊| 101/103 [00:49<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] Batch 100/103                   Loss D: -1.2435, loss G: 0.6764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:50<00:00,  2.05it/s]\n",
      " 98%|█████████▊| 101/103 [00:46<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] Batch 100/103                   Loss D: -1.3002, loss G: 0.6437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:46<00:00,  2.20it/s]\n",
      " 98%|█████████▊| 101/103 [00:45<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] Batch 100/103                   Loss D: -1.2605, loss G: 0.6081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:46<00:00,  2.21it/s]\n",
      " 98%|█████████▊| 101/103 [00:46<00:01,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] Batch 100/103                   Loss D: -1.2905, loss G: 0.6233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:47<00:00,  2.19it/s]\n",
      " 98%|█████████▊| 101/103 [00:46<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] Batch 100/103                   Loss D: -1.2170, loss G: 0.6326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:46<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "\n",
    "# Hyperparameters etc\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 5e-5\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 3\n",
    "Z_DIM = 128\n",
    "NUM_EPOCHS = 20\n",
    "FEATURES_CRITIC = 64\n",
    "FEATURES_GEN = 64\n",
    "CRITIC_ITERATIONS = 5\n",
    "WEIGHT_CLIP = 0.01\n",
    "\n",
    "\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "\n",
    "dataset = datasets.DatasetFolder(\n",
    "    root=\"flower_data/\",\n",
    "    loader=torchvision.datasets.folder.default_loader,\n",
    "    extensions=('.jpg', '.jpeg', '.png', '.bmp'),  \n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# initialize gen and disc/critic\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)\n",
    "\n",
    "# initializate optimizer\n",
    "opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n",
    "opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# for tensorboard plotting\n",
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0\n",
    "\n",
    "# Check if saved files exist and load them\n",
    "generator_path = \"generator.pth\"\n",
    "critic_loss_path = \"critic_loss.pth\"\n",
    "gen_loss_path = \"gen_loss.pth\"\n",
    "\n",
    "if os.path.exists(generator_path):\n",
    "    gen.load_state_dict(torch.load(generator_path))\n",
    "if os.path.exists(critic_loss_path):\n",
    "    critic_loss = torch.load(critic_loss_path)\n",
    "if os.path.exists(gen_loss_path):\n",
    "    gen_loss = torch.load(gen_loss_path)\n",
    "\n",
    "gen.train()\n",
    "critic.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Target labels not needed! <3 unsupervised\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(loader)):\n",
    "        data = data.to(device)\n",
    "        cur_batch_size = data.shape[0]\n",
    "\n",
    "        # Train Critic: max E[critic(real)] - E[critic(fake)]\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            critic_real = critic(data).reshape(-1)\n",
    "            critic_fake = critic(fake).reshape(-1)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "            # clip critic weights between -0.01, 0.01\n",
    "            for p in critic.parameters():\n",
    "                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n",
    "\n",
    "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
    "        gen_fake = critic(fake).reshape(-1)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0 and batch_idx > 0:\n",
    "            gen.eval()\n",
    "            critic.eval()\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
    "                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    data[:32], normalize=True\n",
    "                )\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:32], normalize=True\n",
    "                )\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1\n",
    "            gen.train()\n",
    "            critic.train()\n",
    "\n",
    "    # Save generator, critic loss, and generator loss\n",
    "    torch.save(gen.state_dict(), generator_path)\n",
    "    torch.save(loss_critic.item(), critic_loss_path)\n",
    "    torch.save(loss_gen.item(), gen_loss_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Load the generator model\n",
    "generator = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "generator.load_state_dict(torch.load(\"generator.pth\"))\n",
    "generator.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate flower images\n",
    "num_images = 10  # Number of images to generate\n",
    "fixed_noise = torch.randn(num_images, Z_DIM, 1, 1).to(device)\n",
    "with torch.no_grad():\n",
    "    generated_images = generator(fixed_noise).detach().cpu()\n",
    "\n",
    "# Save the generated images\n",
    "save_image(generated_images, \"generated_flowers.png\", nrow=5, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
